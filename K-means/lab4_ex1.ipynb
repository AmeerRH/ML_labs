{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import regular expressins packge\n",
        "# import numbers package\n",
        "# supress system warnings\n",
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import mode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "v5RsxHiM2hsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readFile(fileName):\n",
        "    file = open(fileName,'r',encoding=\"cp437\")\n",
        "    fileText = \"\"\n",
        "    for line in file:\n",
        "        fileText += line\n",
        "    return fileText"
      ],
      "metadata": {
        "id": "fTGCLQt72hpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess text\n",
        "def preProcess(text):\n",
        "# Remove non-letter chars\n",
        "    text = re.sub(\"[^a-zA-Z ]\",\" \", text)\n",
        "# Change characters to lower\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "dVaxug2i2hnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a word set of a given text\n",
        "def genReferenceWordList(texts,stopWords):\n",
        "# concatenate the texts\n",
        "    allText = \"\"\n",
        "    for line in texts:\n",
        "        allText += line\n",
        "    # Generate a word list\n",
        "    wordsList =  allText.split()\n",
        "    # Generate a word set\n",
        "    wordsSet =  set(wordsList)\n",
        "    # Remove the stop words from the word list\n",
        "    stopWordsList = stopWords.split()\n",
        "    stopWordsSet = set(stopWordsList)\n",
        "    refWordSet = wordsSet.difference(stopWordsSet)\n",
        "    return list(refWordSet)"
      ],
      "metadata": {
        "id": "-vG1IrRm2hka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word frequency\n",
        "def getWordFrequency(texts,refList):\n",
        "\n",
        "    refListSize = len(refList)\n",
        "    nTexts = len(texts)\n",
        "    wordFreq = np.empty((nTexts,refListSize),dtype=np.int64)\n",
        "    for i in range(nTexts):            # scan texts\n",
        "        print(\"text\" + str(i))\n",
        "        for j in range(refListSize):      # scan words in dict\n",
        "            wordFreq[i,j] = texts[i].count(refList[j])\n",
        "    return wordFreq"
      ],
      "metadata": {
        "id": "YkEx2IyK2hfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Partition the text into a list of chunks of size windSize\n",
        "def partitionText(text, windSize,label):\n",
        "    nParts = len(text)//windSize\n",
        "    chunks=[]\n",
        "    labels = []\n",
        "    for i in range(nParts):\n",
        "        nextWind = i*windSize\n",
        "        nextChunk = text[nextWind:nextWind+windSize]\n",
        "        chunks += [nextChunk]\n",
        "        labels += [label]\n",
        "    return chunks,labels;"
      ],
      "metadata": {
        "id": "WA6dAKrU2hcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot labels in bar chart\n",
        "def plotLabels(labels,labelsType):\n",
        "\n",
        "    plt.title(\"The \" +  labelsType + \" labels\")\n",
        "    plt.xlabel(\"partition#\")\n",
        "    plt.ylabel(\"label\")\n",
        "    plt.bar(range(len(labels)),labels)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uvSWbJKA2hZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rearange predicted labels\n",
        "# according to the most common true label\n",
        "def rearangeLabels(trueLabels,predLabels,k):\n",
        "    rearangedLabels = np.zeros(len(trueLabels))\n",
        "    for i in range(k):\n",
        "        predIs = np.where((i+1)==predLabels)[0]\n",
        "        # Get the true labels in the predicted locations\n",
        "        trueLabelsInLoc = trueLabels[predIs]\n",
        "        # find the common label\n",
        "        commonLabel,count = mode(trueLabelsInLoc)\n",
        "        # put the comon true label in the predicted location\n",
        "        rearangedLabels[predIs] = commonLabel\n",
        "    return rearangedLabels"
      ],
      "metadata": {
        "id": "6EF0piQH2hWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bookTexts = []\n",
        "#read  and preprocess files\n",
        "bookTexts += [readFile('DB.txt')]\n",
        "bookTexts += [readFile('HP.txt')]"
      ],
      "metadata": {
        "id": "bOJfWig_2hT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "for text in bookTexts:\n",
        "    texts += [preProcess(text)]"
      ],
      "metadata": {
        "id": "JTbpb8sp2hRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read stop words file - words that can be removed\n",
        "stopWords = readFile('stopwords_en.txt')"
      ],
      "metadata": {
        "id": "qBJAdnHt2hOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dictionary\n",
        "refList = genReferenceWordList(texts,stopWords)"
      ],
      "metadata": {
        "id": "7M8I9VoV2hL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wind - chunks size\n",
        "window = 50000"
      ],
      "metadata": {
        "id": "2P-p9ExS3J4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "trueLabels = []\n",
        "for i, text in enumerate(texts):\n",
        "    newChunks,newLabels = partitionText(text , window,i+1)\n",
        "    chunks += newChunks\n",
        "    trueLabels+=newLabels"
      ],
      "metadata": {
        "id": "st7pQksy3J1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trueLabels = np.array(trueLabels)\n",
        "plotLabels(trueLabels,\"true\")"
      ],
      "metadata": {
        "id": "y_DWlkg33_Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordFreq = getWordFrequency(chunks,refList)"
      ],
      "metadata": {
        "id": "7JKdBA6i4B1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster with kmeans\n",
        "k = len(bookTexts) # k: number of clusters"
      ],
      "metadata": {
        "id": "Cu98p6RR3Oqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the k-means object\n",
        "kmeans = KMeans(n_clusters = k)\n",
        "# compute the k-means model of the chunks\n",
        "kmeans.fit(wordFreq)"
      ],
      "metadata": {
        "id": "WbzGHreV3OoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the labels of the chunks\n",
        "predLabels = kmeans.predict(wordFreq)\n",
        "predLabels +=1"
      ],
      "metadata": {
        "id": "mbqQfwEV3T-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the k-means prediction\n",
        "plotLabels(predLabels,\"k-means\")"
      ],
      "metadata": {
        "id": "lGkMSGVb3T2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rearange predicted labels according to the true labels\n",
        "predictedLabels = rearangeLabels(trueLabels,predLabels,k)\n",
        "plotLabels(predictedLabels,\"k-means rearanged\")"
      ],
      "metadata": {
        "id": "KaLj4V0J2hJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}